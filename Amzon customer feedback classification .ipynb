{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Final_Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "247710    0\n",
       "247711    1\n",
       "247712    1\n",
       "247713    0\n",
       "247714    0\n",
       "Name: Helpfulness_Label, Length: 247715, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Helpfulness_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec \n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Body']=df['Review_Body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cleaned_review_body=df['Review_Body'].str.replace('[^a-zA-Z]',\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review=cleaned_review_body.str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [love, these, brushes, and, very, soft, founda...\n",
       "1         [I, don, t, suffer, from, acne, However, I, su...\n",
       "2                                            [Great, socks]\n",
       "3         [I, got, absolutely, no, instructions, with, m...\n",
       "4         [These, pliers, are, a, great, find, for, fish...\n",
       "                                ...                        \n",
       "247710                              [Product, as, promised]\n",
       "247711    [Locks, securely, but, the, combo, is, horribl...\n",
       "247712    [i, totally, LOVE, it, at, last, i, can, enjoy...\n",
       "247713    [Amazing, smell, Arrived, before, ETA, Really,...\n",
       "247714    [Fits, over, mat, perfectly, No, slipping, on,...\n",
       "Name: Review_Body, Length: 247715, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ameli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review=cleaned_review.apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer= SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_review_body=cleaned_review_body.apply(lambda x: [stemmer.stem(word) for word in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review=cleaned_review.apply(lambda x: [word for word in x if len(word)>3 and len(word)<12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [love, these, brush, veri, soft, foundat, brus...\n",
       "1         [suffer, from, howev, suffer, from, compuls, s...\n",
       "2                                             [great, sock]\n",
       "3         [absolut, instruct, with, vinyl, assum, heat, ...\n",
       "4         [these, plier, great, find, fishermen, they, e...\n",
       "                                ...                        \n",
       "247710                                    [product, promis]\n",
       "247711    [lock, secur, combo, horribl, bought, this, mo...\n",
       "247712    [total, love, last, enjoy, coffe, worri, about...\n",
       "247713    [amaz, smell, arriv, befor, realli, satisfi, p...\n",
       "247714    [over, perfect, slip, your, sweat, great, prod...\n",
       "Name: Review_Body, Length: 247715, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned_review_body.apply(lambda x: [word.replace('\\i$', 'y') for word in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Word2Vec(cleaned_review_body, min_count=2,size= 100,workers=3, window =3, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = api.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=[sen for sen in df['Review_Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=\" \".join(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "cleaned_review=df['Review_Body'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review=cleaned_review.apply(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review=cleaned_review.apply(lambda x:[word for word in x if len(word)>3 and len(word)<12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review=cleaned_review.apply(lambda x:[word for word in x if word not in\n",
    "stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_list = [model_1[word] for word in tokens if word in model_1.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = [word for word in tokens if word in model_1.vocab]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_zip = zip(words_list, vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_dict = dict(word_vec_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_w2vec = pd.DataFrame.from_dict(word_vec_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_w2vec.to_csv('vectoriezed_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_w2vec=pd.read_csv(\"vectoriezed_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_w2vec=df_vectorized_w2vec.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components = 2, init = 'random', random_state = 10, perplexity = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = tsne.fit_transform(df_vectorized_w2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df=pd.DataFrame(tsne_df)\n",
    "tsne_df.to_csv(\"tnse_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    \n",
    "    doc = [word for word in doc if word in model_1.vocab]\n",
    "    return np.mean(model_1[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] \n",
    "    #doc = [word for word in doc if len(word)>4 and len(word)<12]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_docs(corpus, texts, condition_on_doc):\n",
    "    \n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    if texts is not None:\n",
    "        texts = [text for (text, doc) in zip(texts, corpus)\n",
    "                 if condition_on_doc(doc)]\n",
    "\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, texts,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list_1=[doc for doc in df['Review_Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list=[doc for doc in df['Review_Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review_body_1=[preprocess(i) for i in review_list_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    #text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word.isalpha()] \n",
    "    doc = [word for word in doc if len(word)>3 and len(word)<12]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review=[process_text(i) for i in df['Review_Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review_body_2=[preprocess(i) for i in review_list_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654 docs removed\n"
     ]
    }
   ],
   "source": [
    "cleaned_review_body_1, review_list_1 = filter_docs(cleaned_review_body_1, review_list_1, lambda doc: has_vector_representation(model_1, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247715"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "cleaned_review_body_1, review_list_1 = filter_docs(cleaned_review_body_1, review_list_1, lambda doc: (len(doc) != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenized_1=[TreebankWordDetokenizer().detokenize(word) for word in cleaned_review_body_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenized_2=[TreebankWordDetokenizer().detokenize(word) for word in cleaned_review_body_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenized_removed=pd.DataFrame(detokenized_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenized_original=pd.DataFrame(detokenized_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247061, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenized_removed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = []\n",
    "for doc in cleaned_review_body_1: \n",
    "    x.append(document_vector(model_1, doc))\n",
    "    \n",
    "X = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.335593</td>\n",
       "      <td>-0.183956</td>\n",
       "      <td>0.084420</td>\n",
       "      <td>0.182747</td>\n",
       "      <td>0.095725</td>\n",
       "      <td>0.084332</td>\n",
       "      <td>0.139901</td>\n",
       "      <td>-0.098358</td>\n",
       "      <td>0.049651</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092017</td>\n",
       "      <td>0.050891</td>\n",
       "      <td>0.239327</td>\n",
       "      <td>-0.400130</td>\n",
       "      <td>-0.044502</td>\n",
       "      <td>-0.609984</td>\n",
       "      <td>-0.123225</td>\n",
       "      <td>-0.118359</td>\n",
       "      <td>-0.098331</td>\n",
       "      <td>0.388853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057332</td>\n",
       "      <td>-0.145008</td>\n",
       "      <td>-0.077507</td>\n",
       "      <td>0.099913</td>\n",
       "      <td>-0.001726</td>\n",
       "      <td>0.239505</td>\n",
       "      <td>0.195212</td>\n",
       "      <td>-0.205908</td>\n",
       "      <td>-0.074108</td>\n",
       "      <td>-0.073762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098827</td>\n",
       "      <td>0.053384</td>\n",
       "      <td>0.253159</td>\n",
       "      <td>0.074217</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>-0.202337</td>\n",
       "      <td>-0.085835</td>\n",
       "      <td>0.039945</td>\n",
       "      <td>0.114929</td>\n",
       "      <td>0.032494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240265</td>\n",
       "      <td>-0.449910</td>\n",
       "      <td>0.255430</td>\n",
       "      <td>0.216341</td>\n",
       "      <td>0.294065</td>\n",
       "      <td>0.479560</td>\n",
       "      <td>0.316960</td>\n",
       "      <td>-0.016728</td>\n",
       "      <td>-0.342130</td>\n",
       "      <td>-0.328275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.251695</td>\n",
       "      <td>0.200127</td>\n",
       "      <td>-0.170105</td>\n",
       "      <td>-0.555197</td>\n",
       "      <td>-0.660350</td>\n",
       "      <td>0.013435</td>\n",
       "      <td>0.210020</td>\n",
       "      <td>-0.193558</td>\n",
       "      <td>-0.017185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102460</td>\n",
       "      <td>0.034363</td>\n",
       "      <td>-0.035178</td>\n",
       "      <td>-0.003887</td>\n",
       "      <td>0.102370</td>\n",
       "      <td>0.165402</td>\n",
       "      <td>0.198205</td>\n",
       "      <td>-0.185169</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>-0.133081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155108</td>\n",
       "      <td>0.207881</td>\n",
       "      <td>0.054062</td>\n",
       "      <td>-0.164022</td>\n",
       "      <td>0.103973</td>\n",
       "      <td>-0.031730</td>\n",
       "      <td>-0.151994</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>0.048025</td>\n",
       "      <td>0.083719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122722</td>\n",
       "      <td>-0.046204</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>-0.031691</td>\n",
       "      <td>-0.045783</td>\n",
       "      <td>-0.017736</td>\n",
       "      <td>0.235787</td>\n",
       "      <td>-0.154965</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>-0.093536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.096963</td>\n",
       "      <td>-0.020856</td>\n",
       "      <td>-0.116877</td>\n",
       "      <td>-0.030589</td>\n",
       "      <td>-0.004493</td>\n",
       "      <td>-0.019890</td>\n",
       "      <td>-0.082874</td>\n",
       "      <td>-0.166574</td>\n",
       "      <td>0.228325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247056</th>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.286215</td>\n",
       "      <td>-0.193237</td>\n",
       "      <td>0.259055</td>\n",
       "      <td>-0.175520</td>\n",
       "      <td>0.259013</td>\n",
       "      <td>0.124567</td>\n",
       "      <td>-0.454435</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>-0.079935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072250</td>\n",
       "      <td>0.261558</td>\n",
       "      <td>0.579485</td>\n",
       "      <td>-0.309292</td>\n",
       "      <td>0.173675</td>\n",
       "      <td>-0.491285</td>\n",
       "      <td>-0.395736</td>\n",
       "      <td>-0.197971</td>\n",
       "      <td>0.289995</td>\n",
       "      <td>0.171095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247057</th>\n",
       "      <td>0.212731</td>\n",
       "      <td>0.135581</td>\n",
       "      <td>0.079503</td>\n",
       "      <td>-0.025656</td>\n",
       "      <td>0.072885</td>\n",
       "      <td>0.118328</td>\n",
       "      <td>0.260708</td>\n",
       "      <td>-0.080643</td>\n",
       "      <td>0.076851</td>\n",
       "      <td>0.041034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156632</td>\n",
       "      <td>0.105361</td>\n",
       "      <td>0.026708</td>\n",
       "      <td>-0.099650</td>\n",
       "      <td>-0.105490</td>\n",
       "      <td>-0.145882</td>\n",
       "      <td>-0.066391</td>\n",
       "      <td>-0.072009</td>\n",
       "      <td>0.037982</td>\n",
       "      <td>-0.032683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247058</th>\n",
       "      <td>-0.169992</td>\n",
       "      <td>0.054092</td>\n",
       "      <td>0.053043</td>\n",
       "      <td>-0.038903</td>\n",
       "      <td>-0.209773</td>\n",
       "      <td>0.197966</td>\n",
       "      <td>0.430321</td>\n",
       "      <td>-0.123014</td>\n",
       "      <td>0.182677</td>\n",
       "      <td>-0.025336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.195696</td>\n",
       "      <td>0.111377</td>\n",
       "      <td>-0.016318</td>\n",
       "      <td>-0.054676</td>\n",
       "      <td>-0.187137</td>\n",
       "      <td>-0.116381</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>-0.117413</td>\n",
       "      <td>-0.224302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247059</th>\n",
       "      <td>0.110455</td>\n",
       "      <td>0.361118</td>\n",
       "      <td>0.070931</td>\n",
       "      <td>-0.050831</td>\n",
       "      <td>0.119876</td>\n",
       "      <td>0.214450</td>\n",
       "      <td>-0.122811</td>\n",
       "      <td>-0.223898</td>\n",
       "      <td>0.089509</td>\n",
       "      <td>-0.222808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043082</td>\n",
       "      <td>0.552421</td>\n",
       "      <td>0.487870</td>\n",
       "      <td>-0.170385</td>\n",
       "      <td>-0.034806</td>\n",
       "      <td>-0.062689</td>\n",
       "      <td>-0.028584</td>\n",
       "      <td>-0.177308</td>\n",
       "      <td>0.224070</td>\n",
       "      <td>-0.187569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247060</th>\n",
       "      <td>0.114889</td>\n",
       "      <td>-0.310480</td>\n",
       "      <td>-0.030609</td>\n",
       "      <td>-0.176067</td>\n",
       "      <td>0.220229</td>\n",
       "      <td>0.579760</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>-0.375443</td>\n",
       "      <td>-0.124311</td>\n",
       "      <td>-0.267636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207105</td>\n",
       "      <td>0.256516</td>\n",
       "      <td>0.366974</td>\n",
       "      <td>-0.393539</td>\n",
       "      <td>-0.280398</td>\n",
       "      <td>-0.263858</td>\n",
       "      <td>0.310211</td>\n",
       "      <td>0.015167</td>\n",
       "      <td>-0.088878</td>\n",
       "      <td>-0.080054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247061 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0      -0.335593 -0.183956  0.084420  0.182747  0.095725  0.084332  0.139901   \n",
       "1       0.057332 -0.145008 -0.077507  0.099913 -0.001726  0.239505  0.195212   \n",
       "2       0.240265 -0.449910  0.255430  0.216341  0.294065  0.479560  0.316960   \n",
       "3       0.102460  0.034363 -0.035178 -0.003887  0.102370  0.165402  0.198205   \n",
       "4       0.122722 -0.046204  0.000785 -0.031691 -0.045783 -0.017736  0.235787   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "247056  0.012715  0.286215 -0.193237  0.259055 -0.175520  0.259013  0.124567   \n",
       "247057  0.212731  0.135581  0.079503 -0.025656  0.072885  0.118328  0.260708   \n",
       "247058 -0.169992  0.054092  0.053043 -0.038903 -0.209773  0.197966  0.430321   \n",
       "247059  0.110455  0.361118  0.070931 -0.050831  0.119876  0.214450 -0.122811   \n",
       "247060  0.114889 -0.310480 -0.030609 -0.176067  0.220229  0.579760  0.001534   \n",
       "\n",
       "              7         8         9   ...        90        91        92  \\\n",
       "0      -0.098358  0.049651 -0.034888  ... -0.092017  0.050891  0.239327   \n",
       "1      -0.205908 -0.074108 -0.073762  ... -0.098827  0.053384  0.253159   \n",
       "2      -0.016728 -0.342130 -0.328275  ...  0.025500  0.251695  0.200127   \n",
       "3      -0.185169  0.080159 -0.133081  ... -0.155108  0.207881  0.054062   \n",
       "4      -0.154965  0.019299 -0.093536  ...  0.004821  0.096963 -0.020856   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "247056 -0.454435  0.060769 -0.079935  ... -0.072250  0.261558  0.579485   \n",
       "247057 -0.080643  0.076851  0.041034  ... -0.156632  0.105361  0.026708   \n",
       "247058 -0.123014  0.182677 -0.025336  ...  0.036232  0.195696  0.111377   \n",
       "247059 -0.223898  0.089509 -0.222808  ...  0.043082  0.552421  0.487870   \n",
       "247060 -0.375443 -0.124311 -0.267636  ...  0.207105  0.256516  0.366974   \n",
       "\n",
       "              93        94        95        96        97        98        99  \n",
       "0      -0.400130 -0.044502 -0.609984 -0.123225 -0.118359 -0.098331  0.388853  \n",
       "1       0.074217  0.025746 -0.202337 -0.085835  0.039945  0.114929  0.032494  \n",
       "2      -0.170105 -0.555197 -0.660350  0.013435  0.210020 -0.193558 -0.017185  \n",
       "3      -0.164022  0.103973 -0.031730 -0.151994  0.021097  0.048025  0.083719  \n",
       "4      -0.116877 -0.030589 -0.004493 -0.019890 -0.082874 -0.166574  0.228325  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "247056 -0.309292  0.173675 -0.491285 -0.395736 -0.197971  0.289995  0.171095  \n",
       "247057 -0.099650 -0.105490 -0.145882 -0.066391 -0.072009  0.037982 -0.032683  \n",
       "247058 -0.016318 -0.054676 -0.187137 -0.116381 -0.025897 -0.117413 -0.224302  \n",
       "247059 -0.170385 -0.034806 -0.062689 -0.028584 -0.177308  0.224070 -0.187569  \n",
       "247060 -0.393539 -0.280398 -0.263858  0.310211  0.015167 -0.088878 -0.080054  \n",
       "\n",
       "[247061 rows x 100 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.DataFrame(review_list)\n",
    "r.to_csv('r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_1=pd.DataFrame(review_list_1)\n",
    "r_1.to_csv('r_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components = 2, init = 'random', random_state = 10, perplexity = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = tsne.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df=pd.DataFrame(tsne_df)\n",
    "final_removed=pd.concat([detokenized_removed,tsne_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[df['Helpfulness_Label'][i]]) for i, _d in enumerate(cleaned_review)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow = Doc2Vec(dm=1, vector_size=25, negative=5, hs=0, min_count=2, sample = 0, workers=cores, alpha=0.025, min_alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.train(tagged_data,total_examples=len(tagged_data), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.save('d2v_25.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=gensim.models.Doc2Vec.load(\"d2v_25.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_alpha=0.01\n",
    "infer_epoch=50\n",
    "X=[]\n",
    "for d in cleaned_review:\n",
    "     \n",
    "    X.append( m.infer_vector(d, alpha=start_alpha, steps=infer_epoch) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.size(X,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_csv('X_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df=pd.read_csv('X_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df=X_df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmean = KMeans(n_clusters=25, random_state=0)\n",
    "kmean_cluster=kmean.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters']=kmean_cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247710</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247711</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247712</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247713</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247714</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247715 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clusters\n",
       "0              8\n",
       "1             20\n",
       "2              1\n",
       "3             22\n",
       "4             10\n",
       "...          ...\n",
       "247710         5\n",
       "247711        13\n",
       "247712         2\n",
       "247713        24\n",
       "247714         4\n",
       "\n",
       "[247715 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['clusters']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [love, brushes, soft, foundation, brush, washe...\n",
       "1         [suffer, acne, however, suffer, compulsive, sk...\n",
       "2                                            [great, socks]\n",
       "3         [absolutely, vinyl, assumed, heat, vinyl, coul...\n",
       "4         [these, pliers, great, find, fishermen, they, ...\n",
       "                                ...                        \n",
       "247710                                  [product, promised]\n",
       "247711    [locks, securely, combo, horrible, bought, mou...\n",
       "247712    [totally, love, last, enjoy, coffee, worry, an...\n",
       "247713    [amazing, smell, arrived, really, satisfied, p...\n",
       "247714    [fits, perfectly, slipping, sweat, great, prod...\n",
       "Name: Review_Body, Length: 247715, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 always\n",
      "1 brush\n",
      "2 brushes\n",
      "3 cosmetic\n",
      "4 eyeliner\n",
      "5 eyeshadow\n",
      "6 foundation\n",
      "7 good\n",
      "8 harsh\n",
      "9 little\n",
      "10 love\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in cleaned_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x1ef9df95a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "LDA_text = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase=True, preprocessor = lambda x: x, tokenizer = lambda\n",
    "x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_vectorized=vectorizer.fit_transform(cleaned_review).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
